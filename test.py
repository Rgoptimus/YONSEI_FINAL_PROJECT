# -*- coding: utf-8 -*-
"""Incidence of Crime Risk Mapping Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kt4Sbrk-A1uMyzYDbOHmUEEUs3zLEO89

# IoC Risk Mapping Analysis

This dataset represents a comprehensive record of crime incidents within the City of Los Angeles, starting from 2020. The data is sourced from original crime reports, which were originally typed on paper, introducing the possibility of some inaccuracies. Certain location fields may contain missing data denoted as (0°, 0°). To prioritize privacy, address fields are limited to the nearest hundred block. While the data is generally reliable, any questions or concerns can be addressed through comments. Explore this dataset to uncover trends, patterns, and gain a deeper understanding of crime in Los Angeles.

Data Understanding:

1. 'DR_NO' : CaseID
2. 'Date Rptd' : Reported Date
3. 'DATE OCC' : Date Occured
4. 'TIME OCC' : Time Occured
5. 'AREA' : Area of Crime
6. 'AREA NAME' : Name of The Area
7. 'Rpt Dist No' : District Number of Incident
8. 'Part 1-2'
9. 'Crm Cd' : Police Code for Crime
10. 'Crm Cd Desc' : Crime Description
11. 'Mocodes' : Mocodes
12. 'Vict Age' : Victim Age
13. 'Vict Sex' : Victim Gender
14. 'Vict Descent' : Victim Descent
15. 'Premis Cd' : Premis Code
16. 'Premis Desc' : Premis Description
17. 'Weapon Used Cd' : Weapon Used Code
18. 'Weapon Desc' : Weapon Used Description
19. 'Status' : Status Code
20. 'Status Desc' : Status Description
21. 'Crm Cd 1' : CRM code 1
22. 'Crm Cd 2' : CRM code 2
23. 'Crm Cd 3' : CRM code 3
24. 'Crm Cd 4' : CRM code 4
25. 'LOCATION' : Location
26. 'Cross Street' : Cross Street
27. 'LAT' : Lat
28. 'LON' : Long

## Data Gathering, Data Understanding, and Data Exploration
"""

import requests
from io import StringIO
import pandas as pd
import numpy as np
import datetime
import io

import xgboost as xgb
from sklearn.metrics import mean_squared_error

from google.colab import drive
drive.mount('/content/drive')
from ipywidgets import interact_manual

import streamlit as st

# File path to the CSV file in Google Drive
file_path = '/content/drive/My Drive/Colab Notebooks/FINAL_PROJECT/Crime_Data_from_2020_to_Present.csv'

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_path)

# Remove time from date rptd and date occ
df['Date Rptd'] = df['Date Rptd'].str[:19]
df['DATE OCC'] = df['DATE OCC'].str[:19]

df.head()

# Show columns name
df.columns

# Show dataframe information
df.info()

# Show area name in Los Angeles
print("List Area Name: ", df['AREA'].unique())

# Count unique values for each column and show the values
unique_value_counts = df.nunique()

# Display the count of unique values for each column
print(unique_value_counts)

# Visualization Area Name VS Count of Incidence Crime
# Count the occurrences of each unique area name
area_name_counts = df['AREA NAME'].value_counts()

# Sort the data by the count of occurrences (highest to lowest)
area_name_counts_sorted = area_name_counts.sort_values(ascending=False)

# Plot the bar plot
sns.barplot(data=df, x=area_name_counts_sorted.values, y=area_name_counts_sorted.index)

# Add labels and title
plt.xlabel('Area Name')
plt.ylabel('Count Incidence of Crime')
plt.title('Total Occured Incidence of Crime by Area Name')

# Display the plot
plt.show()

"""Berdasarkan data diatas area **Central** pada Los Angeles memiliki tingkat pelaporan terjadinya Crime paling banyak sekitar 50.000, kemudian **77th Street** dengan total kasus kisaran 47.000, dan paling sedikit terjadi pada area **Foothill**.

Pengetahuan lebih lanjut dilakukan dengan melihat karakteristik victim yang terjadi pada kekerasan di Los Angeles. Dikarenakan umur yang tertera pada data tersebut merupakan angka satuan, dan banyaknya jumlah angka yang berbeda. Peneliti akan mengkategorikan umur berdasarkan The American Medical Associations’ age.

The American Medical Associations’ age designations:

* Neonates or newborns (birth to 1 month)
* Infants (1 month to 1 year)
* Children (1 year through 12 years)
* Adolescents (13 years through 17 years. They may also be referred to as teenagers depending on the context.)
* Adults (18 years or older)
* Older adults (65 and older)*
"""

# Visualization Victim Age VS Incidence of Crime

# Define the age ranges and corresponding labels
age_ranges = [0, 1, 13, 18, 65, float('inf')]  # The last element 'float('inf')' represents ages above 65
age_labels = ['Neonates', 'Infants', 'Children', 'Adolescents', 'Adults']

# Use pd.cut() to categorize the age based on the defined age ranges and labels
df['Age Category'] = pd.cut(df['Vict Age'], bins=age_ranges, labels=age_labels, right=False)

# Count the occurrences of each unique age category
age_category_counts = df['Age Category'].value_counts()

# Plot the bar plot
sns.barplot(data=df, x=age_category_counts.index, y=age_category_counts.values)

# Add labels and title
plt.xlabel('Age Category')
plt.ylabel('Count Incidence of Violence')
plt.title('Total Occured Incidence of Violence by Age Category')

# Display the plot
plt.show()

"""Berdasarkan data diatas, jumlah insiden kejahatan sering sekali terjadi pada orang yang berusia remaja dengan kisaran umur 13 - 17 tahun.

Dalam pengexploran selanjutnya, peneliti akan membuat plot untuk melihat jumlah kejahatan yang terjadi berdasarkan gender.
"""

# Visualization Victim Gender VS Incidence of Crime
# Get the count of occurrences for each category in 'Vict Sex'
sex_counts = df['Vict Sex'].value_counts()

# Plot the pie chart
plt.pie(sex_counts, labels=sex_counts.index, autopct='%1.1f%%', startangle=90)

# Add labels and title
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Distribution of Victim Sex')
plt.show()

"""Berdasarkan pie chart diatas, dapat dilihat bahwa Laki - Laki (47.6%) sering mendapatkan insiden kejahatan dibandingkan perempuan (42.5%)"""

# Convert datetime column

df['Date Rptd'] = pd.to_datetime(df['Date Rptd'], format = '%m/%d/%Y %H:%M:%S')
df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], format = '%m/%d/%Y %H:%M:%S')

"""Let's plot over the time VS Incidence of Crime"""

# See the max and the min date of the report and the crime occured

print("The maximum date reported: ", max(df['Date Rptd']))
print("The minimum date reported: ", min(df['Date Rptd']))
print("-----------------------------------------------")
print("The maximum date occured: ", max(df['DATE OCC']))
print("The minimum date occured: ", min(df['DATE OCC']))

"""Based on macrotrends, Los Angeles populations in 2020 - 2023:


1. LA (2020): 12,447,000
2. LA (2021): 12,459,000
3. LA (2022): 12,488,000
4. LA (2023): 12,534,000

Source: https://www.macrotrends.net/cities/23052/los-angeles/population#:~:text=The%20current%20metro%20area%20population,a%200.1%25%20increase%20from%202020.
"""

# Extract the year from 'DATE OCC'
df['year_rptd'] = df['Date Rptd'].dt.year

count_year_rptd = df['year_rptd'].value_counts()

# Create crime dataframe
crime_df = pd.DataFrame({'Year': count_year_rptd.index, 'Count': count_year_rptd.values})

# Create Population Dataframe
year = pd.Series([2020,2021,2022,2023], name = 'Year')
population = pd.Series([12447000,12459000,12488000,12534000], name = 'population')

pop_df = pd.concat([year, population], axis = 1)

# Merge crim and population dataframe
rate_df = crime_df.merge(pop_df, how = "left", on = 'Year' )

# Calculate crime rate
rate_df['crime_rate'] = (rate_df['Count']/rate_df['population']) * 100000

rate_df.sort_values(by = 'Year', ascending = True)

"""Conclusion:

1. Kejahatan paling banyak terjadi didaerah central Los Angeles dengan angka kejahatan berkisar 50.000 insiden (dari tahun 2020 - 2023)
2. Korban kejahatan paling banyak didominasi oleh laki - laki sebesar 47.6%
3. Angka kejahatan terus meningkat dari tahun 2020 - 2023 (Catatan: total kejahatan pada tahun 2023 belum semua terhitung)

Dalam meningkatkan keamanan di kota Los Angeles, peneliti ingin membuat prediksi forecasting jumlah kejahatan yang mungkin terjadi pada beberapa area di kota Los Angeles. Kemudian peneliti akan memetakan daerah yang rawan akan kejahatan sehingga dapat digunakan oleh polisi untuk memberikan perhatian lebih pada area tersebut.

# Incidence of Crime Forecasting
"""

# See the trends
# Count incidence of crime by the time
count_date = df[['Date Rptd']].value_counts()

# Plot the trend
count_date.plot(style= '.', figsize=(15,5))

"""By the graph above, menunjukkan bahwa dari tahun 2020 hingga 2023 data menunjukkan trend Curvilinear Trend (Quadratic, Exponential)

## Data Pre processing
"""

# Create New Dataframe
ioc_df = df[['Date Rptd','AREA']]

# Group by date rptd and area name
ioc_df = ioc_df.groupby(['Date Rptd', 'AREA']).size().reset_index(name='Count')

ioc_df.head()

# Convert datetime into split date
def creature_features(ioc_df):
    """
    Create time series features based on time series index
    """
    ioc_df = ioc_df.copy()
    ioc_df['hour'] = ioc_df['Date Rptd'].dt.hour
    ioc_df['dayofweek'] = ioc_df['Date Rptd'].dt.dayofweek
    ioc_df['quarter'] = ioc_df['Date Rptd'].dt.quarter
    ioc_df['month'] = ioc_df['Date Rptd'].dt.month
    ioc_df['year'] = ioc_df['Date Rptd'].dt.year
    ioc_df['dayofyear'] = ioc_df['Date Rptd'].dt.dayofyear
    return ioc_df

ioc_df = creature_features(ioc_df)

ioc_df.info()

# Count unique values for each column and show the values
unique_value_counts = ioc_df.nunique()

# Display the count of unique values for each column
print(unique_value_counts)

sns.boxplot(data=ioc_df, x = 'month', y = 'Count', palette = 'Blues')
plt.title('Incidence by Month')
plt.show()

sns.boxplot(data=ioc_df, x = 'year', y = 'Count', palette = 'Blues')
plt.title('Incidence by Year')
plt.show()

"""## Modelling"""

# Train and test split by time
train = ioc_df.loc[ioc_df['Date Rptd'] < '01-01-2023 00:00:00']
test = ioc_df.loc[ioc_df['Date Rptd'] >= '01-01-2023 00:00:00']


print("Total training point: ", len(train))
print("Total test point: ", len(test))

# Feature and target separatation

FEATURES = ['AREA','dayofweek','quarter','month','year','dayofyear']
TARGET = 'Count'

# Train and Test Split

X_train = train[FEATURES]
y_train = train[TARGET]

X_test = test[FEATURES]
y_test = test[TARGET]

# Modelling
reg = xgb.XGBRegressor(n_estimators = 1000, learning_rate = 0.01,
                      early_stopping_rounds=50)
reg.fit(X_train, y_train,
       eval_set=[(X_train, y_train), (X_test,y_test)],
       verbose=True)

# Get the underlying booster model
booster = reg.get_booster()

# Get the feature importances using the 'get_score()' method
feature_importances = booster.get_score(importance_type='weight')

# Convert the feature importances to a DataFrame
fi = pd.DataFrame({'importance': list(feature_importances.values())},
                  index=list(feature_importances.keys()))

# Sort the DataFrame by importance in descending order
fi = fi.sort_values(by='importance', ascending=False)

# Display the DataFrame to see the feature importances
print(fi)

"""## Forecast on Test"""

test['prediction']= reg.predict(X_test).round()

new_ioc_df = ioc_df.merge(test[['prediction']], how = 'left', left_index=True, right_index=True)

# Set 'Date Rptd' as the index of the DataFrame
new_ioc_df.set_index('Date Rptd', inplace=True)

# Plot the data and prediction
ax = new_ioc_df[['Count']].plot(figsize=(15, 5))
new_ioc_df['prediction'].plot(ax=ax, style='-')
plt.legend(['Truth Data', 'Predictions'])
ax.set_title('Raw data and prediction')

# Show X-axis labels as datetime
ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y %H:%M:%S'))

plt.show()

"""## Evaluation"""

# Calculate RMSE evaluation between real data and prediction data
print("RMSE: ", np.sqrt(mean_squared_error(test['Count'], test['prediction'])))

"""## Improving Model

### Cross Validation
"""

# Remodelling

from sklearn.model_selection import TimeSeriesSplit

tss = TimeSeriesSplit(n_splits=7)
fold = 0
preds = []
scores = []

for train_idx, test_idx in tss.split(ioc_df):
    train = ioc_df.iloc[train_idx]
    test = ioc_df.iloc[test_idx]

    FEATURES = ['AREA','dayofweek','quarter','month','year','dayofyear']
    TARGET = 'Count'

    X_train = train[FEATURES]
    y_train = train[TARGET]

    X_test = test[FEATURES]
    y_test = test[TARGET]

    reg = xgb.XGBRegressor(base_score = 0.5, booster='gbtree',
                          n_estimators=1000,
                          objective='reg:linear',
                          max_depth=3,
                          learning_rate=0.01)
    reg.fit(X_train, y_train,
           eval_set=[(X_train, y_train), (X_test, y_test)],
           verbose=100)

    y_pred = reg.predict(X_test)
    preds.append(y_pred)
    score = np.sqrt(mean_squared_error(y_test, y_pred))
    scores.append(score)

print(f'Score across folds {np.mean(scores):0.4f}')
print(f'Fold scores: {scores}')

"""## Predicting Future

Using User Interface
"""

# Function to output prediction based on user input
def predict_user_input(AREA,
                       dayofweek,
                       quarter,
                       month,
                       year,
                       dayofyear):
    # Reshape the user input into a 2-dimensional numpy array
    user_input = np.array([[AREA, dayofweek, quarter, month, year, dayofyear]])

    # Use the XGBoost model to predict on the user input
    prediction = reg.predict(user_input).round(0)

    return prediction[0]  # Return the predicted value

# Using ipywidgets to take user input
interact_manual(predict_user_input,
                AREA={'Central': 1, 'Rampart': 2, 'Southwest': 3, 'Hollenbeck': 4, 'Harbor': 5,
                      'Hollywood': 6, 'Wilshire': 7, 'West LA': 8, 'Van Nuys': 9, 'West Valley': 10,
                      'Northeast': 11, '77th Street': 12, 'Newton': 13, 'Pacific': 14, 'N Hollywood': 15,
                      'Foothill': 16, 'Devonshire': 17, 'Southeast': 18, 'Mission': 19, 'Olympic': 20,
                      'Topanga': 21},
                dayofweek=(0, 6),
                quarter=(1, 4),
                month=(1, 12),
                year=(2020, 2025),
                dayofyear=(1, 366))

"""Using dataframe"""

# define date range
future_date = pd.date_range('2023-07-10', '2023-12-31')

# define area
all_areas = np.arange(1, 22)

# Create a list of dictionaries containing all possible combinations of date and AREA
data = []
for date in future_date:
    for area in all_areas:
        data.append({'Date Rptd': date, 'AREA': area})

# Create a DataFrame from the list of dictionaries
fut_df = pd.DataFrame(data)

# conver Date Rptd
fut_df = creature_features(fut_df)



new = fut_df[['AREA','dayofweek','quarter','month','year','dayofyear']]

new.head()

new['pred'] = reg.predict(new).round(0)

new.info()

fut_df.info()

# Merge the DataFrames based on their index
merged_df = fut_df.merge(new, left_index=True, right_index=True, suffixes=('_fut', '_new'))

# Drop the duplicate 'Date Rptd' column
merged_df.drop(columns=['AREA_new'], inplace=True)

# Rename the 'Date Rptd_new' column to 'datetime'
merged_df.rename(columns={'AREA_fut': 'AREA'}, inplace=True)

merged_df = merged_df[['Date Rptd', 'AREA', 'pred']]

merged_df

# Function to output prediction based on user input
def predict_user_input(AREA,
                       dayofweek,
                       quarter,
                       month,
                       year,
                       dayofyear):
    # Reshape the user input into a 2-dimensional numpy array
    user_input = np.array([[AREA, dayofweek, quarter, month, year, dayofyear]])
    
    # Use the XGBoost model to predict on the user input (replace 'reg' with your actual model)
    prediction = reg.predict(user_input).round(0)
    
    return prediction[0]  # Return the predicted value

def main():
    st.title("Crime Prediction App")
    st.write("Enter the following parameters to predict the crime:")

    # Using streamlit's slider and selectbox widgets to take user input
    AREA = st.selectbox("Select Area", ['Central', 'Rampart', 'Southwest', 'Hollenbeck', 'Harbor',
                                        'Hollywood', 'Wilshire', 'West LA', 'Van Nuys', 'West Valley',
                                        'Northeast', '77th Street', 'Newton', 'Pacific', 'N Hollywood',
                                        'Foothill', 'Devonshire', 'Southeast', 'Mission', 'Olympic',
                                        'Topanga'])

    dayofweek = st.slider("Select Day of Week", 0, 6)
    quarter = st.slider("Select Quarter", 1, 4)
    month = st.slider("Select Month", 1, 12)
    year = st.slider("Select Year", 2020, 2025)
    dayofyear = st.slider("Select Day of Year", 1, 366)

    # Button to trigger the prediction
    if st.button("Predict"):
        prediction = predict_user_input(AREA, dayofweek, quarter, month, year, dayofyear)
        st.write(f"Predicted crime: {prediction}")

if __name__ == "__main__":
    main()
